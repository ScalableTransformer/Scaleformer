{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import random\r\n",
    "import torch\r\n",
    "import scaleformer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open(\"data/sentence_pairs.txt\", encoding=\"utf-8\") as file:\r\n",
    "    data = file.read().split(\"\\n\")\r\n",
    "    en, fr = zip(*[d.lower().split(\"\\t\") for d in data if len(d) > 0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training input's tokenizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "try:\r\n",
    "    tokenizer_in = scaleformer.BytePairEncoder.load(\"files/tokenizer_in.json\")\r\n",
    "except:\r\n",
    "    tokenizer_in = scaleformer.BytePairEncoder()\r\n",
    "    subwords_en = tokenizer_in.train(en, min_frequency=1.0E-7, max_tokens=5000, prune=True)\r\n",
    "    tokenizer_in.save(\"files/tokenizer_in.json\", overwrite=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training target's tokenizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "try:\r\n",
    "    tokenizer_out = scaleformer.BytePairEncoder.load(\"files/tokenizer_out.json\")\r\n",
    "except:\r\n",
    "    tokenizer_out = scaleformer.BytePairEncoder()\r\n",
    "    subwords_fr = tokenizer_out.train(fr, min_frequency=1.0E-7, max_tokens=5000, prune=True)\r\n",
    "    tokenizer_out.save(\"files/tokenizer_out.json\", overwrite=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from importlib import reload\r\n",
    "scaleformer = reload(scaleformer)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Converting dataset to tensors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "try:\r\n",
    "    x_train = torch.load(\"files/x_train.pty\")\r\n",
    "    y_train = torch.load(\"files/y_train.pty\")\r\n",
    "    x_val = torch.load(\"files/x_val.pty\")\r\n",
    "    y_val = torch.load(\"files/y_val.pty\")\r\n",
    "except:\r\n",
    "    x = scaleformer.strings_to_tensor(en, tokenizer_in)\r\n",
    "    y = scaleformer.strings_to_tensor(fr, tokenizer_out)\r\n",
    "    indexes = list(range(len(x)))\r\n",
    "    random.shuffle(indexes)\r\n",
    "    lim = int(round(0.8*len(x)))\r\n",
    "    i_train, i_val = indexes[:lim], indexes[lim:]\r\n",
    "    x_train, y_train = x[i_train], y[i_train]\r\n",
    "    x_val, y_val = x[i_val], y[i_val]\r\n",
    "    torch.save(x_train, \"files/x_train.pty\")\r\n",
    "    torch.save(y_train, \"files/y_train.pty\")\r\n",
    "    torch.save(x_val, \"files/x_val.pty\")\r\n",
    "    torch.save(y_val, \"files/y_val.pty\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = scaleformer.Transformer(tokenizer_in, tokenizer_out, 6, 64, 4, dropout=0., scalable=True)\r\n",
    "model.to(\"cuda:0\")\r\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1.0E-3)\r\n",
    "train_losses, val_losses, best_epoch = scaleformer.train_loop(model, optimizer, (x_train, y_train), (x_val, y_val), n_epochs=1000, patience=100, batch_size=100)\r\n",
    "torch.save(model, \"files/model.pty\")\r\n",
    "torch.save(optimizer, \"files/optimizer.pty\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Display results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scaleformer.plot_loss(train_losses, val_losses, best_epoch)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 64-bit"
  },
  "interpreter": {
   "hash": "ffae60fc32e1eb18810544c9e351f5d30d0793c406085c3b5f77f89fb6ac6bca"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}