{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training and testing Scaleformer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import random\n",
    "import warnings\n",
    "import torch\n",
    "\n",
    "try:\n",
    "    from scaleformer import BytePairEncoder\n",
    "    from scaleformer import Transformer\n",
    "    from scaleformer import strings_to_tensor\n",
    "    from scaleformer import train_loop\n",
    "    from scaleformer import plot_loss\n",
    "except ImportError:\n",
    "    import sys\n",
    "    sys.path.insert(0, '..')\n",
    "    from scaleformer import BytePairEncoder\n",
    "    from scaleformer import Transformer\n",
    "    from scaleformer import strings_to_tensor\n",
    "    from scaleformer import train_loop\n",
    "    from scaleformer import plot_loss\n",
    "\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "%matplotlib inline                                                                              "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if torch.cuda.is_available():\n",
    "    !nvidia-smi"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open(\"../data/sentence_pairs.txt\", encoding=\"utf-8\") as fp:\n",
    "    data = fp.read().split(\"\\n\")\n",
    "    en, fr = zip(*[d.lower().split(\"\\t\") for d in data if len(d) > 0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training input's tokenizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "try:\n",
    "    tokenizer_in = BytePairEncoder.load(\"tokenizer/tokenizer_in.json\")\n",
    "except:\n",
    "    tokenizer_in = BytePairEncoder()\n",
    "    subwords_en = tokenizer_in.train(en, min_frequency=1.0e-07,\n",
    "                                     max_tokens=5000, prune=True)\n",
    "    tokenizer_in.save(\"tokenizer/tokenizer_in.json\", overwrite=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training target's tokenizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "try:\n",
    "    tokenizer_out = BytePairEncoder.load(\"tokenizer/tokenizer_out.json\")\n",
    "except:\n",
    "    tokenizer_out = BytePairEncoder()\n",
    "    subwords_fr = tokenizer_out.train(fr, min_frequency=1.0e-07,\n",
    "                                      max_tokens=5000, prune=True)\n",
    "    tokenizer_out.save(\"tokenizer/tokenizer_out.json\", overwrite=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Converting dataset to tensors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "try:\n",
    "    x_train = torch.load(\"models/x_train.pty\")\n",
    "    y_train = torch.load(\"models/y_train.pty\")\n",
    "    x_val = torch.load(\"models/x_val.pty\")\n",
    "    y_val = torch.load(\"models/y_val.pty\")\n",
    "except:\n",
    "    x = strings_to_tensor(en, tokenizer_in)\n",
    "    y = strings_to_tensor(fr, tokenizer_out)\n",
    "\n",
    "    indexes = list(range(len(x)))\n",
    "    random.shuffle(indexes)\n",
    "\n",
    "    lim = int(round(0.8 * len(x)))\n",
    "    i_train, i_val = indexes[:lim], indexes[lim:]\n",
    "    x_train, y_train = x[i_train], y[i_train]\n",
    "    x_val, y_val = x[i_val], y[i_val]\n",
    "\n",
    "    torch.save(x_train, \"models/x_train.pty\")\n",
    "    torch.save(y_train, \"models/y_train.pty\")\n",
    "    torch.save(x_val, \"models/x_val.pty\")\n",
    "    torch.save(y_val, \"models/y_val.pty\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_train = (x_train, y_train)\n",
    "data_valid = (x_val, y_val)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model = Transformer(tokenizer_in, tokenizer_out, n_stages=6,\n",
    "                    projection_dim=64, n_heads=4, dropout=0.0,\n",
    "                    scalable=True)\n",
    "model.to(\"cuda:0\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1.0e-03)\n",
    "\n",
    "\n",
    "with warnings.catch_warnings(record=True) as w:\n",
    "    warnings.simplefilter(\"always\")\n",
    "    rets = train_loop(model, optimizer, data_train, data_valid,\n",
    "                    n_epochs=1000, patience=100, batch_size=10)\n",
    "    train_losses, val_losses, best_epoch = rets\n",
    "\n",
    "torch.save(model, \"models/model.pty\")\n",
    "torch.save(optimizer, \"models/optimizer.pty\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Display results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_loss(train_losses, val_losses, best_epoch)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Use in production"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "new_model = torch.load(\"models/model.pty\").to(\"cpu\")\n",
    "new_model.predict(\"Tom is gone\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}